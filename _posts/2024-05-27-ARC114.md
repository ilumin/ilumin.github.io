---
title: ARC114 - Analyze Speech & Language with Google APIs
layout: post
date: 2024-05-27
description: ARC114
tags: gcp, chaiyo2024
categories: gcp-labs
---

# ARC114: Analyze Speech & Language with Google APIs: Challenge Lab

## Setup

```shell
export PROJECT_ID=$(gcloud config get-value core/project)
```

## Task 1: Create an API key

```shell
gcloud alpha services api-keys create --display-name="lumin"
export KEY_NAME=$(gcloud alpha services api-keys list --format="value(name)" --filter "displayName=lumin")
export API_KEY=$(gcloud alpha services api-keys get-key-string $KEY_NAME --format="value(keyString)")
```

## Task 2: Make an entity analysis request and call the Natural Language API

```shell
cat > nl_request.json <<EOF
{
  "document":{
    "type":"PLAIN_TEXT",
    "content":"With approximately 8.2 million people residing in Boston, the capital city of Massachusetts is one of the largest in the United States."
  },
  "encodingType":"UTF8"
}
EOF

curl "https://language.googleapis.com/v1/documents:analyzeEntities?key=${API_KEY}" \
  -s -X POST -H "Content-Type: application/json" --data-binary @nl_request.json > nl_response.json
```

## Task 3. Create a speech analysis request and call the Speech API

```shell
cat > speech_request.json <<EOF
{
  "config": {
      "encoding":"FLAC",
      "languageCode": "en-US"
  },
  "audio": {
      "uri":"gs://cloud-samples-tests/speech/brooklyn.flac"
  }
}
EOF

curl -s -X POST -H "Content-Type: application/json" --data-binary @speech_request.json \
"https://speech.googleapis.com/v1/speech:recognize?key=${API_KEY}" > speech_response.json
```

## Task 4. Analyze sentiment with the Natural Language API

Update `def analyze()`

```shell
cat > sentiment_analysis.py <<EOF
import argparse

from google.cloud import language_v1

def print_result(annotations):
    score = annotations.document_sentiment.score
    magnitude = annotations.document_sentiment.magnitude

    for index, sentence in enumerate(annotations.sentences):
        sentence_sentiment = sentence.sentiment.score
        print(
            "Sentence {} has a sentiment score of {}".format(index, sentence_sentiment)
        )

    print(
        "Overall Sentiment: score of {} with magnitude of {}".format(score, magnitude)
    )
    return 0

def analyze(movie_review_filename):
    """Run a sentiment analysis request on text within a passed filename."""
    client = language_v1.LanguageServiceClient()

    with open(movie_review_filename) as review_file:
        content = review_file.read()

    document = language_v1.Document(
        content=content, type_=language_v1.Document.Type.PLAIN_TEXT
    )
    annotations = client.analyze_sentiment(request={"document": document})

    print_result(annotations)


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description=__doc__, formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument(
        "movie_review_filename",
        help="The filename of the movie review you'd like to analyze.",
    )
    args = parser.parse_args()

    analyze(args.movie_review_filename)
EOF
```

Then

```shell
# copy file
gsutil cp gs://cloud-samples-tests/natural-language/sentiment-samples.tgz .
gunzip sentiment-samples.tgz
tar -xvf sentiment-samples.tar

# Run
python3 sentiment_analysis.py reviews/bladerunner-pos.txt
```
